{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming+And+Its+Types-+Text+Preprocessing**"
      ],
      "metadata": {
        "id": "20NwQ6YXmado"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85314bdd"
      },
      "source": [
        "## Introduction to Stemming\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GjP2TUtkoJ0"
      },
      "source": [
        "## Stemming\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcc12c76"
      },
      "source": [
        "## Stemming\n",
        "Stemming is a fundamental text normalization technique in natural language processing (NLP) and natural language understanding (NLU). It involves reducing words to their base or root form, often called a \"stem\" or \"root,\" by removing derivational affixes (prefixes and suffixes).\n",
        "\n",
        "### Importance in NLP/NLU:\n",
        "Stemming plays a crucial role in text preprocessing for several reasons:\n",
        "1.  **Reducing Word Variations:** It helps in mapping different inflected forms of a word (e.g., \"eating,\" \"eats,\" \"eaten\") to a common base form (\"eat\"). This reduces the vocabulary size and ensures that variations of the same word are treated as a single token.\n",
        "2.  **Improving Search and Retrieval:** By stemming queries and documents, search engines can retrieve more relevant results, as a search for \"running\" would also match documents containing \"ran\" or \"runs.\"\n",
        "3.  **Enhancing Model Performance:** For tasks like text classification, sentiment analysis, or topic modeling, stemming can improve model accuracy by preventing words with the same semantic meaning from being treated as distinct features, thereby reducing sparsity and noise.\n",
        "4.  **Data Reduction:** It contributes to data reduction, making subsequent processing steps more efficient and less computationally intensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c0f6b41"
      },
      "source": [
        "## Porter Stemmer Details and Examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d661648"
      },
      "source": [
        "### Porter Stemmer Details and Examples\n",
        "\n",
        "The Porter Stemmer is one of the most widely used and oldest stemming algorithms, developed by Martin Porter in 1980. It's a **rules-based algorithm** that operates by applying a series of rules to a word to reduce it to its root form or 'stem'. It primarily works by removing common morphological and inflexional endings from words in English.\n",
        "\n",
        "**Key Characteristics:**\n",
        "*   **Suffix Stripping:** It systematically removes suffixes like '-ing', '-ed', '-s', '-es', '-ies', etc.\n",
        "*   **Heuristic Approach:** It uses a set of approximately 60 rules, applied in a specific order, to achieve stemming. These rules are designed to be general and cover a broad range of English words.\n",
        "*   **Aggressive Stemming:** The Porter Stemmer is known for its aggressive nature, meaning it often reduces words to shorter, sometimes non-dictionary, stems. For example, 'beautiful' might become 'beauti'. This can sometimes lead to loss of information or stems that are not actual words.\n",
        "*   **Language-Specific:** It is specifically designed for the English language and does not perform well on other languages.\n",
        "\n",
        "**Common Use Cases:**\n",
        "*   **Information Retrieval:** Helps in matching documents to queries by reducing words to a common base form, improving recall.\n",
        "*   **Search Engines:** Used to expand search queries, so a search for 'running' might also match documents containing 'ran' or 'runs'.\n",
        "*   **Text Analysis and NLP:** Simplifies vocabulary and reduces sparsity in text data, which can be beneficial for tasks like text classification, clustering, and topic modeling.\n",
        "\n",
        "**Limitations:**\n",
        "*   **Over-stemming:** Can reduce words too aggressively, sometimes leading to stems that are not linguistically valid words (e.g., 'universal' -> 'univers', 'generous' -> 'gener'). This can sometimes merge words with different meanings into the same stem.\n",
        "*   **Under-stemming:** In some cases, it might fail to reduce words to their common root, leaving distinct words that should be stemmed to the same root (e.g., 'caring' and 'care' might not stem to the same root in some contexts).\n",
        "*   **Not a Lemmatizer:** It's important to distinguish stemming from lemmatization. While stemming chops off suffixes, lemmatization aims to return the base or dictionary form of a word (lemma), which is always a valid word. For example, 'better' would be stemmed to 'better' by Porter, but lemmatized to 'good'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d661743"
      },
      "source": [
        "## Regexp Stemmer Details and Examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92b94e7e"
      },
      "source": [
        "### Regexp Stemmer Explained\n",
        "The `RegexpStemmer` class in NLTK allows for stemming words based on regular expressions. Unlike algorithmic stemmers like Porter or Snowball, which follow predefined rules, `RegexpStemmer` provides a flexible way to remove prefixes or suffixes that match a given regular expression pattern.\n",
        "\n",
        "**Mechanism:**\n",
        "It takes a regular expression as an argument. When `stem()` is called on a word, the stemmer checks if any part of the word (usually a suffix or prefix, depending on the regex) matches the pattern. If a match is found, that part is removed. For example, a pattern like `'ing$|s$|e$|able$'` would remove 'ing', 's', 'e', or 'able' if they appear at the end of a word.\n",
        "\n",
        "**The 'min' Parameter:**\n",
        "The `min` parameter is crucial for controlling the stemming process. It specifies the minimum length a word must have *after* stemming. If applying the regular expression would result in a word shorter than this `min` length, the stemming is not applied. This helps prevent over-stemming and preserves the semantic meaning of shorter words. For instance, if `min=4`, and stemming 'eats' (length 4) by removing 's' would result in 'eat' (length 3), which is less than 4, then 'eats' would remain 'eats'. However, in the provided notebook, it was shown that 'eats' stemmed to 'eat' even with `min=4`, which indicates that `min` applies to the *original* word length, meaning the word must be at least `min` length for stemming to even be considered. Let's clarify this with new examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93650b74",
        "outputId": "478834bb-122a-4103-8ed7-7d1227990167"
      },
      "source": [
        "words_to_test = [\n",
        "    \"running\", \"runs\", \"runner\", \"agreeable\", \"agreement\",\n",
        "    \"apple\", \"eat\", \"eats\", \"cats\", \"dogs\", \"go\", \"goes\", \"able\", \"enable\"\n",
        "]\n",
        "\n",
        "print(\"Demonstrating RegexpStemmer with pattern 'ing$|s$|e$|able$' and min=4:\")\n",
        "for word in words_to_test:\n",
        "    stemmed_word = reg_stemmer.stem(word)\n",
        "    print(f\"{word} ----> {stemmed_word}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demonstrating RegexpStemmer with pattern 'ing$|s$|e$|able$' and min=4:\n",
            "running ----> runn\n",
            "runs ----> run\n",
            "runner ----> runner\n",
            "agreeable ----> agree\n",
            "agreement ----> agreement\n",
            "apple ----> appl\n",
            "eat ----> eat\n",
            "eats ----> eat\n",
            "cats ----> cat\n",
            "dogs ----> dog\n",
            "go ----> go\n",
            "goes ----> goe\n",
            "able ----> \n",
            "enable ----> en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c4141da",
        "outputId": "cafde40b-759c-43ba-afd4-6128733a94ac"
      },
      "source": [
        "prefix_stemmer = RegexpStemmer('^(un|re)', min=4)\n",
        "\n",
        "words_for_prefix_stemming = [\n",
        "    \"unhappy\", \"rethink\", \"undo\", \"rest\", \"understand\", \"read\"\n",
        "]\n",
        "\n",
        "print(\"\\nDemonstrating RegexpStemmer with pattern '^(un|re)' and min=4 (for prefixes):\")\n",
        "for word in words_for_prefix_stemming:\n",
        "    stemmed_word = prefix_stemmer.stem(word)\n",
        "    print(f\"{word} ----> {stemmed_word}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Demonstrating RegexpStemmer with pattern '^(un|re)' and min=4 (for prefixes):\n",
            "unhappy ----> happy\n",
            "rethink ----> think\n",
            "undo ----> do\n",
            "rest ----> st\n",
            "understand ----> derstand\n",
            "read ----> ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ff77b9"
      },
      "source": [
        "## Snowball Stemmer Details and Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "726f3381"
      },
      "source": [
        "### Snowball Stemmer (Porter2)\n",
        "\n",
        "The Snowball Stemmer, also known as the Porter2 Stemmer, is an improved version of the original Porter Stemmer. Developed by Martin Porter, it addresses some of the inconsistencies and limitations of its predecessor, providing more accurate and consistent stemming results.\n",
        "\n",
        "**Improvements over Porter Stemmer:**\n",
        "1.  **Increased Accuracy:** Snowball often produces stems that are closer to the linguistic root and are more consistent. It includes a more extensive set of rules and an additional set of rules for handling common English exceptions.\n",
        "2.  **Better Handling of Vowel/Consonant Combinations:** It has refined rules for handling words with specific vowel and consonant patterns, which can lead to more intuitive stems.\n",
        "3.  **Language Support:** A significant advantage of the Snowball framework is its design to easily implement stemmers for various languages, not just English. While the NLTK implementation typically refers to the English (Porter2) version by default, the underlying framework supports stemmers for many other languages.\n",
        "4.  **Reduced Over-stemming/Under-stemming:** While still aggressive, it aims to strike a better balance, reducing instances where words are stemmed too much (over-stemming) or not enough (under-stemming), compared to the original Porter Stemmer.\n",
        "\n",
        "Like the Porter Stemmer, it is a rules-based suffix-stripping algorithm, but with a more sophisticated and robust set of rules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a952378c"
      },
      "source": [
        "## Comparative Analysis with 5 Distinct Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dca68efc"
      },
      "source": [
        "## Comparative Analysis of Stemmers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3cd5be0",
        "outputId": "7cdf849c-138e-45ca-b114-5eeb5bd48611"
      },
      "source": [
        "words_for_comparison = [\n",
        "    \"beautifully\", \"connection\", \"historical\", \"generously\", \"privileges\",\n",
        "    \"universal\", \"agreement\", \"arguing\", \"better\", \"stemming\"\n",
        "]\n",
        "\n",
        "print(\"Comparative Analysis of Porter, Regexp, and Snowball Stemmers:\\n\")\n",
        "\n",
        "for word in words_for_comparison:\n",
        "    porter_stem = stemming.stem(word)\n",
        "    regexp_stem = reg_stemmer.stem(word)\n",
        "    snowball_stem = snowballsstemmer.stem(word)\n",
        "\n",
        "    print(f\"Original Word: {word:<15}\")\n",
        "    print(f\"  Porter Stemmer:   {porter_stem:<15}\")\n",
        "    print(f\"  Regexp Stemmer:   {regexp_stem:<15}\")\n",
        "    print(f\"  Snowball Stemmer: {snowball_stem:<15}\\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparative Analysis of Porter, Regexp, and Snowball Stemmers:\n",
            "\n",
            "Original Word: beautifully    \n",
            "  Porter Stemmer:   beauti         \n",
            "  Regexp Stemmer:   beautifully    \n",
            "  Snowball Stemmer: beauti         \n",
            "\n",
            "Original Word: connection     \n",
            "  Porter Stemmer:   connect        \n",
            "  Regexp Stemmer:   connection     \n",
            "  Snowball Stemmer: connect        \n",
            "\n",
            "Original Word: historical     \n",
            "  Porter Stemmer:   histor         \n",
            "  Regexp Stemmer:   historical     \n",
            "  Snowball Stemmer: histor         \n",
            "\n",
            "Original Word: generously     \n",
            "  Porter Stemmer:   gener          \n",
            "  Regexp Stemmer:   generously     \n",
            "  Snowball Stemmer: generous       \n",
            "\n",
            "Original Word: privileges     \n",
            "  Porter Stemmer:   privileg       \n",
            "  Regexp Stemmer:   privilege      \n",
            "  Snowball Stemmer: privileg       \n",
            "\n",
            "Original Word: universal      \n",
            "  Porter Stemmer:   univers        \n",
            "  Regexp Stemmer:   universal      \n",
            "  Snowball Stemmer: univers        \n",
            "\n",
            "Original Word: agreement      \n",
            "  Porter Stemmer:   agreement      \n",
            "  Regexp Stemmer:   agreement      \n",
            "  Snowball Stemmer: agreement      \n",
            "\n",
            "Original Word: arguing        \n",
            "  Porter Stemmer:   argu           \n",
            "  Regexp Stemmer:   argu           \n",
            "  Snowball Stemmer: argu           \n",
            "\n",
            "Original Word: better         \n",
            "  Porter Stemmer:   better         \n",
            "  Regexp Stemmer:   better         \n",
            "  Snowball Stemmer: better         \n",
            "\n",
            "Original Word: stemming       \n",
            "  Porter Stemmer:   stem           \n",
            "  Regexp Stemmer:   stemm          \n",
            "  Snowball Stemmer: stem           \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71c5daa0"
      },
      "source": [
        "## Discussion and Comparison\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475265b3"
      },
      "source": [
        "## Discussion and Comparison\n",
        "\n",
        "Based on the comparative examples, we can analyze the characteristics, strengths, and weaknesses of each stemming algorithm:\n",
        "\n",
        "### 1. Porter Stemmer\n",
        "**Strengths:**\n",
        "*   **Aggressive and Widely Used:** It's one of the oldest and most commonly used stemmers, known for its aggressive suffix stripping.\n",
        "*   **Simplicity:** Relatively simple rules-based approach, making it computationally efficient.\n",
        "*   **Standard for English:** Often serves as a baseline for English stemming tasks.\n",
        "\n",
        "**Weaknesses:**\n",
        "*   **Over-stemming:** Tends to reduce words too aggressively, often resulting in stems that are not actual dictionary words (e.g., `beautifully` -> `beauti`, `historical` -> `histor`). This can sometimes lead to loss of semantic meaning.\n",
        "*   **Inconsistency:** Can be inconsistent for certain word variations, merging words with different meanings or failing to merge words that should be stemmed to the same root.\n",
        "*   **English-Specific:** Designed exclusively for the English language.\n",
        "\n",
        "**When to use:** When you need a quick, aggressive, and generally effective stemmer for English text, especially in Information Retrieval where higher recall (matching more documents) is prioritized over precision.\n",
        "\n",
        "### 2. Regexp Stemmer\n",
        "**Strengths:**\n",
        "*   **Flexibility and Control:** Offers complete control over the stemming process by defining custom regular expressions. This is its biggest advantage.\n",
        "*   **Precision:** Can be highly precise if the regex patterns are well-defined for specific use cases.\n",
        "*   **Handles Prefixes/Suffixes:** Capable of removing both prefixes and suffixes, unlike Porter/Snowball which primarily focus on suffixes.\n",
        "*   **Language-Agnostic (with custom rules):** Can be adapted for any language by writing appropriate regex patterns.\n",
        "\n",
        "**Weaknesses:**\n",
        "*   **Manual Rule Definition:** Requires significant manual effort and domain expertise to define effective regular expressions. Poorly defined regex can lead to ineffective or erroneous stemming.\n",
        "*   **Complexity for Comprehensive Stemming:** Creating a comprehensive set of regex rules to mimic the breadth of Porter or Snowball is extremely complex and error-prone.\n",
        "*   **Less Aggressive (by default):** Unless specifically designed, it might not be as aggressive in reducing word forms as algorithmic stemmers.\n",
        "\n",
        "**When to use:** When you have very specific stemming requirements, need to remove particular prefixes or suffixes, or are working with specialized vocabulary where algorithmic stemmers might not perform well. It's excellent for fine-grained control or when dealing with non-standard word structures.\n",
        "\n",
        "### 3. Snowball Stemmer (Porter2)\n",
        "**Strengths:**\n",
        "*   **Improved Accuracy and Consistency:** An evolution of the Porter Stemmer, it addresses many of its inconsistencies, providing more accurate and linguistically sound stems (e.g., `generously` -> `generous` vs. Porter's `gener`).\n",
        "*   **Reduced Over-stemming/Under-stemming:** Strikes a better balance between aggressiveness and linguistic validity compared to the original Porter stemmer.\n",
        "*   **Multi-Language Support:** The Snowball framework allows for implementing stemmers for various languages, making it more versatile globally.\n",
        "*   **Widely Accepted:** Often considered the default choice for English stemming due to its balance of performance and accuracy.\n",
        "\n",
        "**Weaknesses:**\n",
        "*   **Still Aggressive:** While improved, it can still produce non-dictionary words as stems.\n",
        "*   **Rules-Based Limitations:** As a rules-based algorithm, it might struggle with highly irregular words or those not covered by its rule set.\n",
        "\n",
        "**When to use:** This is generally the recommended default choice for English stemming in most NLP applications. It offers a good balance of aggressiveness, accuracy, and broad applicability without requiring manual rule definition, making it suitable for tasks like information retrieval, text classification, and data reduction where a robust, language-specific stemmer is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7be25693"
      },
      "source": [
        "# Data Analysis Key Findings\n",
        "\n",
        "*   **Stemming Definition and Importance:** Stemming is a core NLP technique that reduces words to their root form by removing affixes. Its importance lies in reducing word variations, improving search and retrieval, enhancing model performance, and contributing to data reduction.\n",
        "*   **Porter Stemmer Characteristics:** This is an older, rules-based, aggressive suffix-stripping algorithm designed specifically for English. It is prone to \"over-stemming,\" producing stems that are not actual words (e.g., \"beautifully\" stems to \"beauti\", \"historical\" to \"histor\").\n",
        "*   **Regexp Stemmer Flexibility and `min` Parameter Behavior:** The Regexp Stemmer offers high flexibility through custom regular expressions for both prefixes and suffixes. A key observation was that its `min` parameter applies to the *original word's length* to decide if stemming occurs, not to the resulting stemmed word's length. This can lead to very short or even empty stems (e.g., \"eats\" (length 4) stemmed to \"eat\" (length 3), \"able\" (length 4) stemmed to an empty string, and \"enable\" (length 6) stemmed to \"en\" (length 2) when `min=4`).\n",
        "*   **Snowball Stemmer (Porter2) Improvements:** The Snowball Stemmer is an enhanced version of the Porter Stemmer, offering increased accuracy and consistency. It includes more refined rules for handling vowel/consonant patterns, aims to reduce over-stemming and under-stemming, and supports multiple languages (e.g., \"generously\" stems to \"generous\" with Snowball, compared to Porter's \"gener\").\n",
        "*   **Comparative Performance:**\n",
        "    *   The Regexp Stemmer generally demonstrated less aggressive stemming than Porter and Snowball unless its patterns explicitly matched.\n",
        "    *   Porter and Snowball typically produced more aggressive stemmed forms.\n",
        "    *   Snowball often yielded more linguistically sound stems than Porter in cases like \"generously\" versus \"gener\".\n",
        "    *   Words such as \"agreement\" and \"better\" were often not stemmed by any of the algorithms, indicating they did not match the defined rules or patterns.\n",
        "\n",
        "### Steps\n",
        "\n",
        "*   The choice of stemming algorithm should be guided by the specific NLP task's requirements for aggressiveness and linguistic accuracy. Snowball Stemmer (Porter2) is generally recommended for English due to its improved balance, while Regexp Stemmer provides fine-grained control for highly specific use cases.\n",
        "*   When using Regexp Stemmer, careful consideration of the `min` parameter and its interaction with the original word length is crucial to prevent unintended over-stemming or the generation of excessively short/empty stems.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}