{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41139a9a"
      },
      "source": [
        "## Introduction to Text Preprocessing and Stopwords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f993d5bf"
      },
      "source": [
        "## Introduction to Text Preprocessing and Stopwords\n",
        "\n",
        "### Text Preprocessing\n",
        "Text preprocessing is a crucial step in Natural Language Processing (NLP) that involves cleaning and transforming raw text data into a more suitable format for analysis and model training. The main purpose of text preprocessing is to reduce noise, improve efficiency, and enhance the quality of features extracted from text, ultimately leading to better performance in NLP tasks.\n",
        "\n",
        "Common steps involved in text preprocessing include:\n",
        "\n",
        "1.  **Tokenization**: Breaking down the text into smaller units, such as words or subwords (tokens).\n",
        "2.  **Lowercasing**: Converting all text to lowercase to treat words like 'The' and 'the' as the same.\n",
        "3.  **Removing Punctuation**: Eliminating punctuation marks (e.g., periods, commas, question marks) that often do not carry significant meaning.\n",
        "4.  **Removing Numbers**: Deciding whether to remove numerical digits, depending on the specific NLP task.\n",
        "5.  **Removing Special Characters**: Getting rid of any non-alphanumeric characters.\n",
        "6.  **Stopword Removal**: Eliminating common words that add little to no semantic value (explained in more detail below).\n",
        "7.  **Stemming**: Reducing words to their root or base form (e.g., 'running' to 'run', 'studies' to 'studi') by chopping off suffixes.\n",
        "8.  **Lemmatization**: Reducing words to their dictionary or morphological base form (e.g., 'better' to 'good', 'ran' to 'run'). Unlike stemming, lemmatization considers the word's context and converts it to its meaningful base form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fec6d72"
      },
      "source": [
        "### Stopwords\n",
        "\n",
        "**Stopwords** are common words in a language that are often filtered out or removed during text preprocessing because they tend to occur very frequently and carry little to no significant meaning for many NLP tasks. These words are typically high-frequency terms like articles, prepositions, conjunctions, and some pronouns.\n",
        "\n",
        "**Examples of common English stopwords include:** \"the\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\".\n",
        "\n",
        "### Why Remove Stopwords?\n",
        "\n",
        "Stopwords are typically removed in NLP tasks for several key reasons:\n",
        "\n",
        "1.  **Reducing Noise and Irrelevant Information**: Stopwords do not usually contribute to the unique meaning or sentiment of a text. For instance, in sentiment analysis, words like 'the' or 'is' don't indicate whether a review is positive or negative. Removing them helps focus on more informative words.\n",
        "2.  **Improving Computational Efficiency**: By removing high-frequency, low-value words, the overall size of the text data is reduced. This leads to faster processing times and lower memory consumption during tasks like indexing, searching, and model training.\n",
        "3.  **Enhancing Model Performance**: In many NLP models, especially those based on statistical methods or bag-of-words representations, stopwords can disproportionately influence word counts and feature vectors. Removing them can improve the signal-to-noise ratio, allowing the model to learn from more meaningful terms and potentially leading to better accuracy and generalization.\n",
        "4.  **Reducing Dimensionality**: When converting text into numerical features (e.g., using TF-IDF or word embeddings), each unique word becomes a dimension. Removing stopwords significantly reduces the number of dimensions, which is beneficial for managing computational complexity and preventing the \"curse of dimensionality\" in machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d48c4b0a"
      },
      "source": [
        "## NLTK Stopword Removal - Step-by-Step Guide\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7be4de15",
        "outputId": "26c2b7c6-4465-46cc-dcce-5e08be959c7a"
      },
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "               the world have come and invaded us, captured our lands, conquered our minds.\n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
        "               We have not grabbed their land, their culture,\n",
        "               their history and tried to enforce our way of life on them.\n",
        "               Why? Because we respect the freedom of others.That is why my\n",
        "               first vision is that of freedom. I believe that India got its first vision of\n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
        "               I see four milestones in my career\"\"\"\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True) # Explicitly download punkt_tab\n",
        "\n",
        "# Get the list of English stopwords\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenize the paragraph\n",
        "tokenized_words = word_tokenize(paragraph)\n",
        "\n",
        "# Create a new list containing words after stopword removal\n",
        "filtered_words = [word.lower() for word in tokenized_words if word.lower() not in english_stopwords]\n",
        "\n",
        "# Print the original tokenized words and the words after stopword removal\n",
        "print(\"Original Tokenized Words:\", tokenized_words)\n",
        "print(\"\\nWords after Stopword Removal:\", filtered_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokenized Words: ['I', 'have', 'three', 'visions', 'for', 'India', '.', 'In', '3000', 'years', 'of', 'our', 'history', ',', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', ',', 'captured', 'our', 'lands', ',', 'conquered', 'our', 'minds', '.', 'From', 'Alexander', 'onwards', ',', 'the', 'Greeks', ',', 'the', 'Turks', ',', 'the', 'Moguls', ',', 'the', 'Portuguese', ',', 'the', 'British', ',', 'the', 'French', ',', 'the', 'Dutch', ',', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', ',', 'took', 'over', 'what', 'was', 'ours', '.', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', '.', 'We', 'have', 'not', 'conquered', 'anyone', '.', 'We', 'have', 'not', 'grabbed', 'their', 'land', ',', 'their', 'culture', ',', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', '.', 'Why', '?', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others.That', 'is', 'why', 'my', 'first', 'vision', 'is', 'that', 'of', 'freedom', '.', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', ',', 'when', 'we', 'started', 'the', 'War', 'of', 'Independence', '.', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', '.', 'If', 'we', 'are', 'not', 'free', ',', 'no', 'one', 'will', 'respect', 'us', '.', 'My', 'second', 'vision', 'for', 'India', '’', 's', 'development', '.', 'For', 'fifty', 'years', 'we', 'have', 'been', 'a', 'developing', 'nation', '.', 'It', 'is', 'time', 'we', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', '.', 'We', 'are', 'among', 'the', 'top', '5', 'nations', 'of', 'the', 'world', 'in', 'terms', 'of', 'GDP', '.', 'We', 'have', 'a', '10', 'percent', 'growth', 'rate', 'in', 'most', 'areas', '.', 'Our', 'poverty', 'levels', 'are', 'falling', '.', 'Our', 'achievements', 'are', 'being', 'globally', 'recognised', 'today', '.', 'Yet', 'we', 'lack', 'the', 'self-confidence', 'to', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', ',', 'self-reliant', 'and', 'self-assured', '.', 'Isn', '’', 't', 'this', 'incorrect', '?', 'I', 'have', 'a', 'third', 'vision', '.', 'India', 'must', 'stand', 'up', 'to', 'the', 'world', '.', 'Because', 'I', 'believe', 'that', 'unless', 'India', 'stands', 'up', 'to', 'the', 'world', ',', 'no', 'one', 'will', 'respect', 'us', '.', 'Only', 'strength', 'respects', 'strength', '.', 'We', 'must', 'be', 'strong', 'not', 'only', 'as', 'a', 'military', 'power', 'but', 'also', 'as', 'an', 'economic', 'power', '.', 'Both', 'must', 'go', 'hand-in-hand', '.', 'My', 'good', 'fortune', 'was', 'to', 'have', 'worked', 'with', 'three', 'great', 'minds', '.', 'Dr.', 'Vikram', 'Sarabhai', 'of', 'the', 'Dept', '.', 'of', 'space', ',', 'Professor', 'Satish', 'Dhawan', ',', 'who', 'succeeded', 'him', 'and', 'Dr.', 'Brahm', 'Prakash', ',', 'father', 'of', 'nuclear', 'material', '.', 'I', 'was', 'lucky', 'to', 'have', 'worked', 'with', 'all', 'three', 'of', 'them', 'closely', 'and', 'consider', 'this', 'the', 'great', 'opportunity', 'of', 'my', 'life', '.', 'I', 'see', 'four', 'milestones', 'in', 'my', 'career']\n",
            "\n",
            "Words after Stopword Removal: ['three', 'visions', 'india', '.', '3000', 'years', 'history', ',', 'people', 'world', 'come', 'invaded', 'us', ',', 'captured', 'lands', ',', 'conquered', 'minds', '.', 'alexander', 'onwards', ',', 'greeks', ',', 'turks', ',', 'moguls', ',', 'portuguese', ',', 'british', ',', 'french', ',', 'dutch', ',', 'came', 'looted', 'us', ',', 'took', '.', 'yet', 'done', 'nation', '.', 'conquered', 'anyone', '.', 'grabbed', 'land', ',', 'culture', ',', 'history', 'tried', 'enforce', 'way', 'life', '.', '?', 'respect', 'freedom', 'others.that', 'first', 'vision', 'freedom', '.', 'believe', 'india', 'got', 'first', 'vision', '1857', ',', 'started', 'war', 'independence', '.', 'freedom', 'must', 'protect', 'nurture', 'build', '.', 'free', ',', 'one', 'respect', 'us', '.', 'second', 'vision', 'india', '’', 'development', '.', 'fifty', 'years', 'developing', 'nation', '.', 'time', 'see', 'developed', 'nation', '.', 'among', 'top', '5', 'nations', 'world', 'terms', 'gdp', '.', '10', 'percent', 'growth', 'rate', 'areas', '.', 'poverty', 'levels', 'falling', '.', 'achievements', 'globally', 'recognised', 'today', '.', 'yet', 'lack', 'self-confidence', 'see', 'developed', 'nation', ',', 'self-reliant', 'self-assured', '.', '’', 'incorrect', '?', 'third', 'vision', '.', 'india', 'must', 'stand', 'world', '.', 'believe', 'unless', 'india', 'stands', 'world', ',', 'one', 'respect', 'us', '.', 'strength', 'respects', 'strength', '.', 'must', 'strong', 'military', 'power', 'also', 'economic', 'power', '.', 'must', 'go', 'hand-in-hand', '.', 'good', 'fortune', 'worked', 'three', 'great', 'minds', '.', 'dr.', 'vikram', 'sarabhai', 'dept', '.', 'space', ',', 'professor', 'satish', 'dhawan', ',', 'succeeded', 'dr.', 'brahm', 'prakash', ',', 'father', 'nuclear', 'material', '.', 'lucky', 'worked', 'three', 'closely', 'consider', 'great', 'opportunity', 'life', '.', 'see', 'four', 'milestones', 'career']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3406549"
      },
      "source": [
        "## Example 1: Basic Sentence Stopword Removal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fce2b788",
        "outputId": "37ca7743-a309-4d4f-8008-9d86c71f8216"
      },
      "source": [
        "sentence = \"This is a very simple sentence to demonstrate stopword removal.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokenized_sentence_words = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Get the list of English stopwords\n",
        "english_stopwords_set = set(stopwords.words('english'))\n",
        "\n",
        "# Create a new list containing words after stopword removal and convert to lowercase\n",
        "filtered_sentence_words = [word.lower() for word in tokenized_sentence_words if word.lower() not in english_stopwords_set]\n",
        "\n",
        "print(f\"Original Sentence: {sentence}\")\n",
        "print(f\"\\nTokenized Words: {tokenized_sentence_words}\")\n",
        "print(f\"\\nFiltered Words (Stopwords Removed): {filtered_sentence_words}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: This is a very simple sentence to demonstrate stopword removal.\n",
            "\n",
            "Tokenized Words: ['This', 'is', 'a', 'very', 'simple', 'sentence', 'to', 'demonstrate', 'stopword', 'removal', '.']\n",
            "\n",
            "Filtered Words (Stopwords Removed): ['simple', 'sentence', 'demonstrate', 'stopword', 'removal', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebb54d9e"
      },
      "source": [
        "## Example 2: Longer Text Stopword Removal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3a43396",
        "outputId": "9e5e1faa-f9fd-40eb-dfec-f3ebc8c536a1"
      },
      "source": [
        "print(\"Original Paragraph:\\n\", paragraph)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            " I have three visions for India. In 3000 years of our history, people from all over\n",
            "               the world have come and invaded us, captured our lands, conquered our minds.\n",
            "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
            "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
            "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
            "               We have not grabbed their land, their culture,\n",
            "               their history and tried to enforce our way of life on them.\n",
            "               Why? Because we respect the freedom of others.That is why my\n",
            "               first vision is that of freedom. I believe that India got its first vision of\n",
            "               this in 1857, when we started the War of Independence. It is this freedom that\n",
            "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
            "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
            "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
            "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
            "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
            "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
            "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
            "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
            "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
            "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
            "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
            "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
            "               I see four milestones in my career\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9a4a415",
        "outputId": "a28100e9-598f-4b9b-fb82-9b87eac24656"
      },
      "source": [
        "print(\"\\nFiltered Words (Stopwords Removed):\", filtered_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtered Words (Stopwords Removed): ['three', 'visions', 'india', '.', '3000', 'years', 'history', ',', 'people', 'world', 'come', 'invaded', 'us', ',', 'captured', 'lands', ',', 'conquered', 'minds', '.', 'alexander', 'onwards', ',', 'greeks', ',', 'turks', ',', 'moguls', ',', 'portuguese', ',', 'british', ',', 'french', ',', 'dutch', ',', 'came', 'looted', 'us', ',', 'took', '.', 'yet', 'done', 'nation', '.', 'conquered', 'anyone', '.', 'grabbed', 'land', ',', 'culture', ',', 'history', 'tried', 'enforce', 'way', 'life', '.', '?', 'respect', 'freedom', 'others.that', 'first', 'vision', 'freedom', '.', 'believe', 'india', 'got', 'first', 'vision', '1857', ',', 'started', 'war', 'independence', '.', 'freedom', 'must', 'protect', 'nurture', 'build', '.', 'free', ',', 'one', 'respect', 'us', '.', 'second', 'vision', 'india', '’', 'development', '.', 'fifty', 'years', 'developing', 'nation', '.', 'time', 'see', 'developed', 'nation', '.', 'among', 'top', '5', 'nations', 'world', 'terms', 'gdp', '.', '10', 'percent', 'growth', 'rate', 'areas', '.', 'poverty', 'levels', 'falling', '.', 'achievements', 'globally', 'recognised', 'today', '.', 'yet', 'lack', 'self-confidence', 'see', 'developed', 'nation', ',', 'self-reliant', 'self-assured', '.', '’', 'incorrect', '?', 'third', 'vision', '.', 'india', 'must', 'stand', 'world', '.', 'believe', 'unless', 'india', 'stands', 'world', ',', 'one', 'respect', 'us', '.', 'strength', 'respects', 'strength', '.', 'must', 'strong', 'military', 'power', 'also', 'economic', 'power', '.', 'must', 'go', 'hand-in-hand', '.', 'good', 'fortune', 'worked', 'three', 'great', 'minds', '.', 'dr.', 'vikram', 'sarabhai', 'dept', '.', 'space', ',', 'professor', 'satish', 'dhawan', ',', 'succeeded', 'dr.', 'brahm', 'prakash', ',', 'father', 'nuclear', 'material', '.', 'lucky', 'worked', 'three', 'closely', 'consider', 'great', 'opportunity', 'life', '.', 'see', 'four', 'milestones', 'career']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5371546"
      },
      "source": [
        "### Observation on Stopword Removal Effect\n",
        "\n",
        "Comparing the original `paragraph` with the `filtered_words` list, several key effects of stopword removal are evident:\n",
        "\n",
        "1.  **Reduced Length**: The `filtered_words` list is significantly shorter than the tokenized version of the original `paragraph`. This reduction in length is a direct result of removing common, high-frequency words that don't carry much semantic value.\n",
        "\n",
        "2.  **Increased Focus on Keywords**: By eliminating stopwords like 'I', 'have', 'for', 'In', 'of', 'our', 'the', 'and', 'us', etc., the remaining words are primarily keywords and content-rich terms. This shifts the focus from grammatical structure and common connectors to the core subjects, actions, and entities mentioned in the text (e.g., 'visions', 'India', 'history', 'world', 'invaded', 'lands', 'conquered', 'minds', 'freedom', 'development', 'strength', 'military', 'economic', 'minds', 'Dr. Vikram Sarabhai', 'Professor Satish Dhawan', 'Dr. Brahm Prakash').\n",
        "\n",
        "3.  **Enhanced Signal-to-Noise Ratio**: For NLP tasks like topic modeling, text classification, or information retrieval, removing stopwords helps improve the signal-to-noise ratio. The algorithms can now concentrate on the more informative words, leading to potentially better performance and more relevant results, as the 'noise' introduced by frequent but less meaningful words is reduced.\n",
        "\n",
        "In essence, stopword removal streamlines the text, making it more concise and emphasizing the critical information, which is beneficial for many analytical applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ccd8fe"
      },
      "source": [
        "## Example 3: Text with Punctuation and Different Casing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46f089f3",
        "outputId": "597b1a59-4f77-405a-f1ab-c41f6fb6444a"
      },
      "source": [
        "mixed_case_text = \"Hello, World! This Is a Test sentence with MiXeD cAsInG and some Punctuation marks, isn't it?\"\n",
        "\n",
        "# Tokenize the mixed_case_text\n",
        "tokenized_mixed_words = nltk.word_tokenize(mixed_case_text)\n",
        "\n",
        "# Filter out English stopwords after converting to lowercase\n",
        "filtered_mixed_case_words = [word.lower() for word in tokenized_mixed_words if word.lower() not in english_stopwords]\n",
        "\n",
        "print(f\"Original Text: {mixed_case_text}\")\n",
        "print(f\"\\nTokenized Words: {tokenized_mixed_words}\")\n",
        "print(f\"\\nFiltered Words (Stopwords Removed): {filtered_mixed_case_words}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello, World! This Is a Test sentence with MiXeD cAsInG and some Punctuation marks, isn't it?\n",
            "\n",
            "Tokenized Words: ['Hello', ',', 'World', '!', 'This', 'Is', 'a', 'Test', 'sentence', 'with', 'MiXeD', 'cAsInG', 'and', 'some', 'Punctuation', 'marks', ',', 'is', \"n't\", 'it', '?']\n",
            "\n",
            "Filtered Words (Stopwords Removed): ['hello', ',', 'world', '!', 'test', 'sentence', 'mixed', 'casing', 'punctuation', 'marks', ',', \"n't\", '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce93e87c"
      },
      "source": [
        "## Example 4: Text with Numerical Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60243115",
        "outputId": "cb0dd9de-d88d-43fb-ff50-474e712038c4"
      },
      "source": [
        "numerical_text = \"The year 2023 was a very important year for many people. There were 10 significant events.\"\n",
        "\n",
        "# Tokenize the numerical_text\n",
        "tokenized_numerical_words = nltk.word_tokenize(numerical_text)\n",
        "\n",
        "# Filter out English stopwords after converting to lowercase\n",
        "filtered_numerical_words = [word.lower() for word in tokenized_numerical_words if word.lower() not in english_stopwords]\n",
        "\n",
        "print(f\"Original Text: {numerical_text}\")\n",
        "print(f\"\\nTokenized Words: {tokenized_numerical_words}\")\n",
        "print(f\"\\nFiltered Words (Stopwords Removed): {filtered_numerical_words}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The year 2023 was a very important year for many people. There were 10 significant events.\n",
            "\n",
            "Tokenized Words: ['The', 'year', '2023', 'was', 'a', 'very', 'important', 'year', 'for', 'many', 'people', '.', 'There', 'were', '10', 'significant', 'events', '.']\n",
            "\n",
            "Filtered Words (Stopwords Removed): ['year', '2023', 'important', 'year', 'many', 'people', '.', '10', 'significant', 'events', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45cfc817"
      },
      "source": [
        "### Discussion: Effect of Stopword Removal on Numerical Data\n",
        "\n",
        "Looking at the output from **Example 4**, we can observe the following regarding numerical data:\n",
        "\n",
        "*   **Original Text**: \"The year 2023 was a very important year for many people. There were 10 significant events.\"\n",
        "*   **Tokenized Words**: `['The', 'year', '2023', 'was', 'a', 'very', 'important', 'year', 'for', 'many', 'people', '.', 'There', 'were', '10', 'significant', 'events', '.']`\n",
        "*   **Filtered Words (Stopwords Removed)**: `['year', '2023', 'important', 'year', 'many', 'people', '.', '10', 'significant', 'events', '.']`\n",
        "\n",
        "As you can see, the numbers `2023` and `10` are present in both the `tokenized_numerical_words` and `filtered_numerical_words` lists. This indicates that **numbers were not removed by the stopword removal process**.\n",
        "\n",
        "##\n",
        "Stopwords, as defined by NLTK's default English list, primarily consist of common grammatical words (articles, prepositions, conjunctions, pronouns, etc.) that typically do not carry significant semantic meaning. Numbers, on the other hand, are generally considered content-bearing tokens, especially in contexts where quantities, dates, or identifiers are important. The standard NLTK `stopwords.words('english')` set does not include numerical digits or numbers as stopwords. Therefore, when filtering based solely on this list, numbers will remain in the processed text. If there was a need to remove numbers, an additional preprocessing step (e.g., using regular expressions to filter out numeric tokens) would be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13badcb2"
      },
      "source": [
        "## Example 5: Custom Stopwords and Language Considerations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f8548a2",
        "outputId": "26012726-23ef-43cf-b175-589d1791aaaa"
      },
      "source": [
        "custom_text = \"This is an example sentence demonstrating custom stopword removal. We will add 'example' and 'demonstrating' as custom stopwords.\"\n",
        "\n",
        "# Get the list of English stopwords\n",
        "english_stopwords_set = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Define custom stopwords\n",
        "custom_stopwords = {'example', 'demonstrating', 'will'}\n",
        "\n",
        "# Combine default and custom stopwords\n",
        "extended_stopwords = english_stopwords_set.union(custom_stopwords)\n",
        "\n",
        "# Tokenize the custom text\n",
        "tokenized_custom_words = nltk.word_tokenize(custom_text)\n",
        "\n",
        "# Filter out words using the extended stopword list\n",
        "filtered_custom_words = [word.lower() for word in tokenized_custom_words if word.lower() not in extended_stopwords]\n",
        "\n",
        "print(f\"Original Text: {custom_text}\")\n",
        "print(f\"\\nTokenized Words: {tokenized_custom_words}\")\n",
        "print(f\"\\nFiltered Words (Default + Custom Stopwords Removed): {filtered_custom_words}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: This is an example sentence demonstrating custom stopword removal. We will add 'example' and 'demonstrating' as custom stopwords.\n",
            "\n",
            "Tokenized Words: ['This', 'is', 'an', 'example', 'sentence', 'demonstrating', 'custom', 'stopword', 'removal', '.', 'We', 'will', 'add', \"'example\", \"'\", 'and', \"'demonstrating\", \"'\", 'as', 'custom', 'stopwords', '.']\n",
            "\n",
            "Filtered Words (Default + Custom Stopwords Removed): ['sentence', 'custom', 'stopword', 'removal', '.', 'add', \"'example\", \"'\", \"'demonstrating\", \"'\", 'custom', 'stopwords', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afe2525"
      },
      "source": [
        "## End Report and Conclusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "474c4e16"
      },
      "source": [
        "## Findings\n",
        "\n",
        "*   **Understanding Text Preprocessing and Stopwords**: Text preprocessing is essential for cleaning and transforming raw text data for NLP tasks, reducing noise, improving efficiency, and enhancing feature quality. Stopwords are common, high-frequency words (e.g., \"the\", \"is\", \"and\") that carry little semantic meaning and are typically removed to reduce noise, improve computational efficiency, enhance model performance, and reduce dimensionality in NLP models.\n",
        "*   **NLTK Stopword Removal Process**: The process involves importing `nltk`, `word_tokenize`, and `stopwords`. Crucially, specific NLTK data resources like 'stopwords', 'punkt', and 'punkt_tab' must be downloaded using `nltk.download()` before use. Tokenization breaks text into words, which are then converted to lowercase and filtered against a set of English stopwords to remove them.\n",
        "*   **Impact on Text Content**: Stopword removal significantly reduces text length and shifts the focus from grammatical connectors to content-rich keywords. For instance, in a given paragraph, words like 'visions', 'India', 'freedom', 'development', 'strength', 'military', and 'economic' were retained, while words like 'I', 'have', 'for', and 'the' were removed. This enhances the signal-to-noise ratio, benefiting tasks like topic modeling or text classification.\n",
        "*   **Handling Text Variations**:\n",
        "    *   **Casing**: Converting words to lowercase (e.g., `word.lower()`) before filtering is critical to ensure that case variations of stopwords (e.g., \"Is\", \"is\") are correctly identified and removed.\n",
        "    *   **Punctuation**: Default NLTK stopword removal does not remove punctuation. Punctuation marks (e.g., '.', ',', '!') and contractions like \"n't\" are retained as separate tokens or parts of tokens after filtering.\n",
        "    *   **Numbers**: Numbers (e.g., '2023', '10') are not considered stopwords by default in NLTK's English list and are therefore preserved during the process, as they often carry significant meaning.\n",
        "*   **Customization and Multilingual Support**:\n",
        "    *   **Custom Stopwords**: Users can extend the default NLTK stopword list with their own domain-specific or custom stopwords (e.g., adding 'example', 'demonstrating', 'will' to the list) to fine-tune the filtering process.\n",
        "    *   **Other Languages**: NLTK provides stopword lists for various languages (e.g., Spanish, French). These can be accessed by specifying the language name (e.g., `stopwords.words('spanish')`), with the requirement to download the specific language corpus if not already present.\n",
        "\n",
        "### Insights\n",
        "\n",
        "*   Always consider the specific NLP task when deciding on stopword removal; while generally beneficial, for tasks sensitive to grammatical structure or negation (e.g., sentiment analysis where \"not good\" vs. \"good\" is critical), a careful approach or custom stopword list may be required.\n",
        "*   For robust preprocessing, integrate additional steps like punctuation removal, numerical filtering, or stemming/lemmatization alongside stopword removal to achieve a cleaner and more task-appropriate text representation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}